{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction \n",
    "The aim of this projcet is to  build  a predictive model for the given data set. Two datasets are provided; train and test data sets. There are 254 features  in for each set and a target value for training set. Ultimately, the goal is to assess predictive accuracy on the test set using the mean squared error metric. \n",
    "\n",
    "Before starting to inspect the data we need to import required tools. We will use `pandas` to inspect the data, and `numpy` and `sklearn` for implementing predictor models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os \n",
    "import time\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import cPickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import scale\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.linear_model import LinearRegression, ElasticNetCV, RidgeCV, LassoCV \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import LinearSVR, NuSVR, SVR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also add the following to suppress warnings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Data Inspection\n",
    "We load train and test data sets and separate `X` and `y` of training set accordingly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_dir = '.'\n",
    "df = pd.read_csv(os.path.join(data_dir, 'codetest_train.txt'), delimiter='\\t')\n",
    "X_test = pd.read_csv(os.path.join(data_dir, 'codetest_test.txt'), delimiter='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start off, we print the head of dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>f_0</th>\n",
       "      <th>f_1</th>\n",
       "      <th>f_2</th>\n",
       "      <th>f_3</th>\n",
       "      <th>f_4</th>\n",
       "      <th>f_5</th>\n",
       "      <th>f_6</th>\n",
       "      <th>f_7</th>\n",
       "      <th>f_8</th>\n",
       "      <th>...</th>\n",
       "      <th>f_244</th>\n",
       "      <th>f_245</th>\n",
       "      <th>f_246</th>\n",
       "      <th>f_247</th>\n",
       "      <th>f_248</th>\n",
       "      <th>f_249</th>\n",
       "      <th>f_250</th>\n",
       "      <th>f_251</th>\n",
       "      <th>f_252</th>\n",
       "      <th>f_253</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.066056</td>\n",
       "      <td>-0.653</td>\n",
       "      <td>0.255</td>\n",
       "      <td>-0.615</td>\n",
       "      <td>-1.833</td>\n",
       "      <td>-0.736</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.115</td>\n",
       "      <td>-0.171</td>\n",
       "      <td>-0.351</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.607</td>\n",
       "      <td>-1.400</td>\n",
       "      <td>-0.920</td>\n",
       "      <td>-0.198</td>\n",
       "      <td>-0.945</td>\n",
       "      <td>-0.573</td>\n",
       "      <td>0.170</td>\n",
       "      <td>-0.418</td>\n",
       "      <td>-1.244</td>\n",
       "      <td>-0.503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.910473</td>\n",
       "      <td>1.179</td>\n",
       "      <td>-0.093</td>\n",
       "      <td>-0.556</td>\n",
       "      <td>0.811</td>\n",
       "      <td>-0.468</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>-0.116</td>\n",
       "      <td>-1.243</td>\n",
       "      <td>1.985</td>\n",
       "      <td>...</td>\n",
       "      <td>1.282</td>\n",
       "      <td>0.032</td>\n",
       "      <td>-0.061</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.061</td>\n",
       "      <td>-0.302</td>\n",
       "      <td>1.281</td>\n",
       "      <td>-0.850</td>\n",
       "      <td>0.821</td>\n",
       "      <td>-0.260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.830711</td>\n",
       "      <td>0.181</td>\n",
       "      <td>-0.778</td>\n",
       "      <td>-0.919</td>\n",
       "      <td>0.113</td>\n",
       "      <td>0.887</td>\n",
       "      <td>-0.762</td>\n",
       "      <td>1.872</td>\n",
       "      <td>-1.709</td>\n",
       "      <td>0.135</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.237</td>\n",
       "      <td>-0.660</td>\n",
       "      <td>1.073</td>\n",
       "      <td>-0.193</td>\n",
       "      <td>0.570</td>\n",
       "      <td>-0.267</td>\n",
       "      <td>1.435</td>\n",
       "      <td>1.332</td>\n",
       "      <td>-1.147</td>\n",
       "      <td>2.580</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 255 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     target    f_0    f_1    f_2    f_3    f_4    f_5    f_6    f_7    f_8  \\\n",
       "0  3.066056 -0.653  0.255 -0.615 -1.833 -0.736    NaN  1.115 -0.171 -0.351   \n",
       "1 -1.910473  1.179 -0.093 -0.556  0.811 -0.468 -0.005 -0.116 -1.243  1.985   \n",
       "2  7.830711  0.181 -0.778 -0.919  0.113  0.887 -0.762  1.872 -1.709  0.135   \n",
       "\n",
       "   ...    f_244  f_245  f_246  f_247  f_248  f_249  f_250  f_251  f_252  f_253  \n",
       "0  ...   -1.607 -1.400 -0.920 -0.198 -0.945 -0.573  0.170 -0.418 -1.244 -0.503  \n",
       "1  ...    1.282  0.032 -0.061    NaN -0.061 -0.302  1.281 -0.850  0.821 -0.260  \n",
       "2  ...   -0.237 -0.660  1.073 -0.193  0.570 -0.267  1.435  1.332 -1.147  2.580  \n",
       "\n",
       "[3 rows x 255 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems the data is mostly in numeric format, including some missing values as well. The target is first column and the rest of columns represent fearures. So we can separate X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = df.iloc[:, 1:]\n",
    "y = df.target\n",
    "y = y.values  # To np.array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Now we need to make sure that all columns of X are in numeric format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set([dtype('O'), dtype('float64')])\n"
     ]
    }
   ],
   "source": [
    "print set(X.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems that we have `dtype('O')` along with `float64` too. So we inspect more those columns separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "column: f_61\n",
      "0    b\n",
      "1    a\n",
      "2    b\n",
      "Name: f_61, dtype: object\n",
      "---------------\n",
      "column: f_121\n",
      "0    D\n",
      "1    A\n",
      "2    B\n",
      "Name: f_121, dtype: object\n",
      "---------------\n",
      "column: f_215\n",
      "0       red\n",
      "1      blue\n",
      "2    orange\n",
      "Name: f_215, dtype: object\n",
      "---------------\n",
      "column: f_237\n",
      "0    Canada\n",
      "1    Canada\n",
      "2    Canada\n",
      "Name: f_237, dtype: object\n",
      "---------------\n"
     ]
    }
   ],
   "source": [
    "categorical_cols = []\n",
    "for col in X.columns:\n",
    "    if X[col].dtype != 'float64':\n",
    "        categorical_cols.append(col)\n",
    "        print 'column:', col \n",
    "        print X[col].head(3)\n",
    "        print '-' * 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, we have a few columns with non-numeric data types (categorical), so we should convert them to numeric ones. Columns to be decoded:  [f_61, f_121, f_215, f_237] should be decoded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We add dummy columns to encode categorical data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f_61</th>\n",
       "      <th>f_121</th>\n",
       "      <th>f_215</th>\n",
       "      <th>f_237</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b</td>\n",
       "      <td>D</td>\n",
       "      <td>red</td>\n",
       "      <td>Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a</td>\n",
       "      <td>A</td>\n",
       "      <td>blue</td>\n",
       "      <td>Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b</td>\n",
       "      <td>B</td>\n",
       "      <td>orange</td>\n",
       "      <td>Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a</td>\n",
       "      <td>C</td>\n",
       "      <td>blue</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b</td>\n",
       "      <td>E</td>\n",
       "      <td>orange</td>\n",
       "      <td>Canada</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  f_61 f_121   f_215   f_237\n",
       "0    b     D     red  Canada\n",
       "1    a     A    blue  Canada\n",
       "2    b     B  orange  Canada\n",
       "3    a     C    blue     USA\n",
       "4    b     E  orange  Canada"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[categorical_cols].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we saw earlier the data inclued missing values too. So we need to fix those raws with null values. We could either remove all raws with missing values but it seems like a good idea, beacuse we will miss majority of data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 254)\n"
     ]
    }
   ],
   "source": [
    "print X.dropna().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So only have 32 samples without missing values. Another approach is to use interploation to fill missing values. We use interpolation with `limit=2` and in both directions to fill null values. We also scale the data such that all values fall in the same interval. This will speed up the training process. The following function performs these 3 operations on the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_data(data, categorical_cols):\n",
    "    \"\"\"Preprocess and clean the data:\n",
    "        * add dummy clumns for categorical values\n",
    "        * fix missing values\n",
    "        * scale \n",
    "    \"\"\"\n",
    "    # dd dummy clumns for categorical values\n",
    "    X_categorical = pd.get_dummies(data[categorical_cols])\n",
    "    X = pd.concat([data.drop(categorical_cols, axis=1), X_categorical], axis=1)\n",
    "    \n",
    "    # Use interpolation to deal with missing values. \n",
    "    X_filled = X.interpolate(limit=2,limit_direction='both').dropna()\n",
    "    \n",
    "    # Scale\n",
    "    X_scaled = pd.DataFrame(data=scale(X_filled), columns=X.columns)\n",
    "    \n",
    "    return X_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_scaled = preprocess_data(X, categorical_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next thing we can try is to use PCA to see if we can reduce the dimension (number of features):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Do some PCA to see if we can reduce the dimension..\n",
    "pca = PCA()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Scale and transform data to get principal components\n",
    "X_reduced = pca.fit_transform(X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 99.96  99.95  99.94  99.93  99.92  99.82  99.72  99.61  99.5   99.39\n",
      "  99.16  98.93  98.7   98.46  98.22  97.98  97.74  97.5   97.26  97.02\n",
      "  96.77  96.52  96.27  96.02  95.77  95.52  95.27  95.01  94.75  94.49\n",
      "  94.23  93.97  93.71  93.45  93.18  92.91  92.64  92.37  92.1   91.83\n",
      "  91.56  91.29  91.01  90.73  90.45  90.17  89.89  89.61  89.33  89.05\n",
      "  88.77  88.49  88.21  87.92  87.63  87.34  87.05  86.76  86.47  86.18\n",
      "  85.89  85.6   85.31  85.01  84.71  84.41  84.11  83.81  83.51  83.21\n",
      "  82.91  82.61  82.3   81.99  81.68  81.37  81.06  80.75  80.44  80.13\n",
      "  79.82  79.51  79.2   78.88  78.56  78.24  77.92  77.6   77.28  76.96\n",
      "  76.64  76.32  76.    75.68  75.35  75.02  74.69  74.36  74.03  73.7\n",
      "  73.37  73.04  72.71  72.37  72.03  71.69  71.35  71.01  70.67  70.33\n",
      "  69.99  69.65  69.31  68.96  68.61  68.26  67.91  67.56  67.21  66.86\n",
      "  66.51  66.16  65.81  65.45  65.09  64.73  64.37  64.01  63.65  63.29\n",
      "  62.93  62.57  62.21  61.84  61.47  61.1   60.73  60.36  59.99  59.62\n",
      "  59.25  58.88  58.51  58.13  57.75  57.37  56.99  56.61  56.23  55.85\n",
      "  55.47  55.08  54.69  54.3   53.91  53.52  53.13  52.74  52.35  51.96\n",
      "  51.57  51.17  50.77  50.37  49.97  49.57  49.17  48.77  48.37  47.97\n",
      "  47.56  47.15  46.74  46.33  45.92  45.51  45.1   44.69  44.28  43.86\n",
      "  43.44  43.02  42.6   42.18  41.76  41.34  40.91  40.48  40.05  39.62\n",
      "  39.19  38.76  38.33  37.9   37.46  37.02  36.58  36.14  35.7   35.26\n",
      "  34.82  34.38  33.93  33.48  33.03  32.58  32.13  31.68  31.23  30.78\n",
      "  30.32  29.86  29.4   28.94  28.48  28.01  27.54  27.07  26.6   26.13\n",
      "  25.66  25.19  24.71  24.23  23.75  23.27  22.79  22.31  21.82  21.33\n",
      "  20.84  20.35  19.86  19.37  18.88  18.38  17.88  17.38  16.88  16.37\n",
      "  15.86  15.35  14.84  14.33  13.82  13.3   12.78  12.26  11.74  11.21\n",
      "  10.68  10.15   9.61   9.07   8.53   7.98   7.43   6.88   6.32   5.76\n",
      "   5.19   4.62   4.01   3.39   2.74   2.08   1.4    0.7 ]\n"
     ]
    }
   ],
   "source": [
    "# Variance (% cumulative) explained by the principal components\n",
    "print np.cumsum(np.round(pca.explained_variance_ratio_, decimals=4) * 100)[::-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "As we can see from above, seems that all components are required to explain the variance in data. So we'll use all components."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the data is cleaned, we are ready to test a few regressors. We create a dictionary called 'models', which includes name to regressor items. By this, we can train all models together and compatre the results to chhose the best performing model. Feel free to uncomment any of models to include in the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "models = {\n",
    "    'LinearRegression': LinearRegression(fit_intercept=True),\n",
    "    'ElasticNetCV': ElasticNetCV(fit_intercept=True,n_jobs=-1),\n",
    "    'LassoCV': LassoCV(n_jobs=-1),\n",
    "    'LinearSVR': LinearSVR(), \n",
    "    'Ridge': RidgeCV(),\n",
    "#     'NuSVR': NuSVR(),\n",
    "    'SVR': SVR(),\n",
    "#     'RFRegressor': RandomForestRegressor(n_estimators=50, n_jobs=-1)  # --> Dangerous! Very time consuming..\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also use cross validation to choose the best model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_folds = 20\n",
    "kf = KFold(X_reduced.shape[0], n_folds=n_folds)\n",
    "err = dict.fromkeys(models.keys(), 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for each model, we run a k-fold cross validation and save the results in a dict, one result for each model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training Ridge ..\n",
      "\t.. 7.50945901871 seconds.\n",
      "training ElasticNetCV ..\n",
      "\t.. 34.6230928898 seconds.\n",
      "training LinearSVR ..\n",
      "\t.. 26.0825669765 seconds.\n",
      "training LinearRegression ..\n",
      "\t.. 3.27368807793 seconds.\n",
      "training LassoCV ..\n",
      "\t.. 32.2397611141 seconds.\n",
      "training SVR ..\n",
      "\t.. 153.611055136 seconds.\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "for model_name, model in models.iteritems():\n",
    "    print 'training', model_name, '..'\n",
    "    t0 = time.time()\n",
    "    for train, test in kf: \n",
    "        model.fit(X_scaled.values[train], y[train])\n",
    "    \n",
    "        p = np.squeeze(map(model.predict, X_scaled.values[test]))\n",
    "        e = p - y[test]\n",
    "        error = np.dot(e,e)\n",
    "        err[model_name] += error\n",
    "\n",
    "    print '\\t..', time.time()-t0, 'seconds.'\n",
    "print 'Done!'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once training is done, we can calculate the `rmse` for each model. The results for 10, and 20 fold cross validations are listed below.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on 20-fold CV:\n",
      "Ridge 5.96842524251\n",
      "ElasticNetCV 3.43133680584\n",
      "LinearSVR 3.47195709737\n",
      "LinearRegression 3.50829586837\n",
      "LassoCV 3.41826205147\n",
      "SVR 3.76794728891\n"
     ]
    }
   ],
   "source": [
    "print 'RMSE on {}-fold CV:'.format(n_folds)\n",
    "for model, error in err.iteritems():\n",
    "    rmse_10cv = np.sqrt(error/X_scaled.shape[0])\n",
    "    print model, rmse_10cv    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### RMSE on 20-fold CV:\n",
    "* Ridge 3.50748745066\n",
    "* ElasticNetCV 3.49292650999\n",
    "* LinearSVR 3.47267712099\n",
    "* LinearRegression 3.50829586837\n",
    "* LassoCV 3.4933509662\n",
    "* SVR 3.76794728891"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best performing model is `RFRegressor` followed by `LassoCV`, both trained on 20-fold cross validation. Considering the training time, which is huge fir `RFRegressor`, we choose second best performing i.e. `LassoCV`. Now we traing a new lassoCV model with all data to use for predicting test data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LassoCV(alphas=None, copy_X=True, cv=20, eps=0.001, fit_intercept=True,\n",
       "    max_iter=1000, n_alphas=100, n_jobs=1, normalize=False, positive=False,\n",
       "    precompute='auto', random_state=None, selection='cyclic', tol=0.0001,\n",
       "    verbose=False)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor = LassoCV(cv=20)\n",
    "regressor.fit(X_scaled, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.46307427, -1.72219849, -0.45683055,  0.04601591,  0.38239376,\n",
       "       -0.14814744])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.coef_[0:6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before using the predictor on test data, we need to make sure that test data has the same format as train. So we call the preprocessing function again, with same settings, to unify data formats. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_test_scaled = preprocess_data(X_test, categorical_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now predict the test data and write the results to a txt file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_test = regressor.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result_file = os.path.join(data_dir, 'prediction.txt')\n",
    "np.savetxt(result_file, y_test, delimiter='\\n', fmt='%1.6f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also get to n features and therir weights: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coef_idx = [i for i in range(len(regressor.coef_))]\n",
    "lst = zip(abs(regressor.coef_), coef_idx)\n",
    "# sort the list \n",
    "lst_sort = sorted(lst, reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 fetures\n",
      "====================\n",
      "f_121_F --> 2.04518250559\n",
      "f_1 --> 1.72219848843\n",
      "f_0 --> 1.46307427022\n",
      "f_6 --> 0.691651119049\n",
      "f_215_red --> 0.632393485903\n",
      "f_215_blue --> 0.605549119951\n",
      "f_27 --> 0.492347223318\n",
      "f_2 --> 0.456830548998\n",
      "f_17 --> 0.399851964329\n",
      "f_4 --> 0.382393761376\n"
     ]
    }
   ],
   "source": [
    "top_n_feats = 10\n",
    "print 'Top {} fetures'.format(top_n_feats)\n",
    "print '=' * 20\n",
    "for i in lst_sort[:10]:\n",
    "    print X_scaled.columns[i[1]] , '-->', i[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Top 10 fetures\n",
    "# ====================\n",
    "# f_175 --> 2.77409249023\n",
    "# f_205 --> 1.70538319659\n",
    "# f_61_e --> 1.24219269182\n",
    "# f_35 --> 0.808882249231\n",
    "# f_218 --> 0.759748432363\n",
    "# f_61_c --> 0.577622944907\n",
    "# f_237_Mexico --> 0.41012307336\n",
    "# f_94 --> 0.33767073516\n",
    "# f_237_Canada --> 0.309637288423\n",
    "# f_195 --> 0.12192988248"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the model into disk:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_model_name = 'Best_model.pkl'\n",
    "with open(os.path.join(data_dir, save_model_name), 'wb') as f: \n",
    "    cPickle.dump(regressor, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load model from disk:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(data_dir, save_model_name), 'rb') as f:\n",
    "    loaded_regressor = cPickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f_0</th>\n",
       "      <th>f_1</th>\n",
       "      <th>f_2</th>\n",
       "      <th>f_3</th>\n",
       "      <th>f_4</th>\n",
       "      <th>f_5</th>\n",
       "      <th>f_6</th>\n",
       "      <th>f_7</th>\n",
       "      <th>f_8</th>\n",
       "      <th>f_9</th>\n",
       "      <th>...</th>\n",
       "      <th>f_121_D</th>\n",
       "      <th>f_121_E</th>\n",
       "      <th>f_121_F</th>\n",
       "      <th>f_215_blue</th>\n",
       "      <th>f_215_orange</th>\n",
       "      <th>f_215_red</th>\n",
       "      <th>f_215_yellow</th>\n",
       "      <th>f_237_Canada</th>\n",
       "      <th>f_237_Mexico</th>\n",
       "      <th>f_237_USA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.654641</td>\n",
       "      <td>0.254037</td>\n",
       "      <td>-0.637801</td>\n",
       "      <td>-1.854237</td>\n",
       "      <td>-0.729256</td>\n",
       "      <td>-0.009611</td>\n",
       "      <td>1.114334</td>\n",
       "      <td>-0.171343</td>\n",
       "      <td>-0.367259</td>\n",
       "      <td>-0.124135</td>\n",
       "      <td>...</td>\n",
       "      <td>2.291288</td>\n",
       "      <td>-0.44614</td>\n",
       "      <td>-0.43741</td>\n",
       "      <td>-0.556405</td>\n",
       "      <td>-0.561335</td>\n",
       "      <td>1.692332</td>\n",
       "      <td>-0.569344</td>\n",
       "      <td>1.407663</td>\n",
       "      <td>-0.679068</td>\n",
       "      <td>-0.701810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.187882</td>\n",
       "      <td>-0.095702</td>\n",
       "      <td>-0.579601</td>\n",
       "      <td>0.830053</td>\n",
       "      <td>-0.461809</td>\n",
       "      <td>-0.009611</td>\n",
       "      <td>-0.117064</td>\n",
       "      <td>-1.252084</td>\n",
       "      <td>2.011519</td>\n",
       "      <td>-1.013727</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.436436</td>\n",
       "      <td>-0.44614</td>\n",
       "      <td>-0.43741</td>\n",
       "      <td>1.797253</td>\n",
       "      <td>-0.561335</td>\n",
       "      <td>-0.590901</td>\n",
       "      <td>-0.569344</td>\n",
       "      <td>1.407663</td>\n",
       "      <td>-0.679068</td>\n",
       "      <td>-0.701810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.184149</td>\n",
       "      <td>-0.784126</td>\n",
       "      <td>-0.937678</td>\n",
       "      <td>0.121417</td>\n",
       "      <td>0.890396</td>\n",
       "      <td>-0.773040</td>\n",
       "      <td>1.871579</td>\n",
       "      <td>-1.721883</td>\n",
       "      <td>0.127641</td>\n",
       "      <td>1.095307</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.436436</td>\n",
       "      <td>-0.44614</td>\n",
       "      <td>-0.43741</td>\n",
       "      <td>-0.556405</td>\n",
       "      <td>1.781466</td>\n",
       "      <td>-0.590901</td>\n",
       "      <td>-0.569344</td>\n",
       "      <td>1.407663</td>\n",
       "      <td>-0.679068</td>\n",
       "      <td>-0.701810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.751389</td>\n",
       "      <td>-0.248462</td>\n",
       "      <td>-1.355928</td>\n",
       "      <td>1.187417</td>\n",
       "      <td>-0.163426</td>\n",
       "      <td>-0.156851</td>\n",
       "      <td>-1.101383</td>\n",
       "      <td>0.227885</td>\n",
       "      <td>1.235565</td>\n",
       "      <td>0.630520</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.436436</td>\n",
       "      <td>-0.44614</td>\n",
       "      <td>-0.43741</td>\n",
       "      <td>1.797253</td>\n",
       "      <td>-0.561335</td>\n",
       "      <td>-0.590901</td>\n",
       "      <td>-0.569344</td>\n",
       "      <td>-0.710397</td>\n",
       "      <td>-0.679068</td>\n",
       "      <td>1.424887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.226101</td>\n",
       "      <td>-1.332855</td>\n",
       "      <td>-0.976149</td>\n",
       "      <td>0.461522</td>\n",
       "      <td>-2.861849</td>\n",
       "      <td>-0.867838</td>\n",
       "      <td>0.602168</td>\n",
       "      <td>0.770272</td>\n",
       "      <td>0.010535</td>\n",
       "      <td>-0.293057</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.436436</td>\n",
       "      <td>2.24145</td>\n",
       "      <td>-0.43741</td>\n",
       "      <td>-0.556405</td>\n",
       "      <td>1.781466</td>\n",
       "      <td>-0.590901</td>\n",
       "      <td>-0.569344</td>\n",
       "      <td>1.407663</td>\n",
       "      <td>-0.679068</td>\n",
       "      <td>-0.701810</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 268 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        f_0       f_1       f_2       f_3       f_4       f_5       f_6  \\\n",
       "0 -0.654641  0.254037 -0.637801 -1.854237 -0.729256 -0.009611  1.114334   \n",
       "1  1.187882 -0.095702 -0.579601  0.830053 -0.461809 -0.009611 -0.117064   \n",
       "2  0.184149 -0.784126 -0.937678  0.121417  0.890396 -0.773040  1.871579   \n",
       "3  0.751389 -0.248462 -1.355928  1.187417 -0.163426 -0.156851 -1.101383   \n",
       "4  1.226101 -1.332855 -0.976149  0.461522 -2.861849 -0.867838  0.602168   \n",
       "\n",
       "        f_7       f_8       f_9    ...       f_121_D  f_121_E  f_121_F  \\\n",
       "0 -0.171343 -0.367259 -0.124135    ...      2.291288 -0.44614 -0.43741   \n",
       "1 -1.252084  2.011519 -1.013727    ...     -0.436436 -0.44614 -0.43741   \n",
       "2 -1.721883  0.127641  1.095307    ...     -0.436436 -0.44614 -0.43741   \n",
       "3  0.227885  1.235565  0.630520    ...     -0.436436 -0.44614 -0.43741   \n",
       "4  0.770272  0.010535 -0.293057    ...     -0.436436  2.24145 -0.43741   \n",
       "\n",
       "   f_215_blue  f_215_orange  f_215_red  f_215_yellow  f_237_Canada  \\\n",
       "0   -0.556405     -0.561335   1.692332     -0.569344      1.407663   \n",
       "1    1.797253     -0.561335  -0.590901     -0.569344      1.407663   \n",
       "2   -0.556405      1.781466  -0.590901     -0.569344      1.407663   \n",
       "3    1.797253     -0.561335  -0.590901     -0.569344     -0.710397   \n",
       "4   -0.556405      1.781466  -0.590901     -0.569344      1.407663   \n",
       "\n",
       "   f_237_Mexico  f_237_USA  \n",
       "0     -0.679068  -0.701810  \n",
       "1     -0.679068  -0.701810  \n",
       "2     -0.679068  -0.701810  \n",
       "3     -0.679068   1.424887  \n",
       "4     -0.679068  -0.701810  \n",
       "\n",
       "[5 rows x 268 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_scaled.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.25455248,  1.30181663, -0.05958967,  0.78721239, -0.26112465,\n",
       "       -0.31078436,  0.68724946,  1.45755675, -0.54018124, -0.3920382 ])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_reduced[0, 0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
